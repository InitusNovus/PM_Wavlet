{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE=128\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CustomDataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.wavelet_files = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wavelet_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wavelet_path = os.path.join(self.root_dir, self.wavelet_files[idx])\n",
    "        wavelet = pd.read_csv(wavelet_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            wavelet = self.transform(wavelet)\n",
    "        return wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Lable in Name\n",
    "## Import Data is 2D Matrix so it need convert matrix to 6*n*m so it need divide 6 to fist size of matrix to get n \n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_root, batch_size=32, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.csv_root = csv_root\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = CustomDataset(self.csv_root)\n",
    "        self.dataset_train, self.dataset_val = random_split(self.dataset,[int(len(self.dataset)*0.7),len(self.dataset)-int(len(self.dataset)*0.7)])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root directory of dataset\n",
    "root_dir = 'path/to/your/dataset'\n",
    "\n",
    "# Define transformations for dataset\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create custom dataset and dataloader\n",
    "data_module = CustomDataModule(root_dir,transforms=transformations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dataloader\n",
    "for batch in data_module:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detective: fake or no fake -> 1 output [0, 1]\n",
    "\n",
    "## TODO : Change the Channel and input size\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the FC layers\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO : Change the Channel and input size\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64)  # [n, 256, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass latent space input into linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)  #256\n",
    "        \n",
    "        # Upsample (transposed conv) 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Upsample to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Convolution to 28x28 (1 feature map)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jm538\\Desktop\\Code\\ML_study\\Gan_ex.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGAN\u001b[39;00m(pl\u001b[39m.\u001b[39mLightningDataModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, latent_dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jm538/Desktop/Code/ML_study/Gan_ex.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class GAN(pl.LightningDataModule):\n",
    "    def __init__(self, latent_dim=100, lr=0.0002):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        \n",
    "        # random noise\n",
    "        \n",
    "        self.validation_z= torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    \n",
    "    def adverarial_loss(self, y_hat,y):\n",
    "        return F.binary_cross_entropy(y_hat,y)\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_dim, optimizer_idx):   \n",
    "        real_imgs, _ = batch\n",
    "        # sample noise\n",
    "        \n",
    "        z= torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "        z= z.type_as(real_imgs)\n",
    "        \n",
    "        # train generator : max log(D(G(z)))\n",
    "       \n",
    "       ## TODO Change the input Data using the label\n",
    "        \n",
    "        if optimizer_idx==0:\n",
    "            fake_imgs=self(z)\n",
    "            y_hat = self.discriminator(fake_imgs)\n",
    "            \n",
    "            y = torch.ones(real_imgs.size[0], 1)\n",
    "            z= z.type_as(real_imgs)\n",
    "            \n",
    "            g_loss =self.adverarial_loss(y_hat, y)\n",
    "            \n",
    "            log_dict = {\"g_loss\" : g_loss }\n",
    "            return {\"loss\": g_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "        \n",
    "        # train discriminator : max log(D(x)) + log(1-D(G(z)))\n",
    "                        \n",
    "        if optimizer_idx== 1:\n",
    "            \n",
    "            # how well can it label as real\n",
    "            y_hat_real = self.discriminator(real_imgs)\n",
    "            \n",
    "            y_real = torch.ones(real_imgs.size[0], 1)\n",
    "            \n",
    "            y_real = y_real.type_as(real_imgs)\n",
    "            \n",
    "            real_loss = self.adverarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            # how well can it label as fake\n",
    "            y_hat_fake =self.discriminator(self(z))\n",
    "            \n",
    "            y_fake = torch.ones(real_imgs.size[0], 1)\n",
    "            y_fake = y_fake.type_as(real_imgs)\n",
    "            \n",
    "            \n",
    "            fake_loss =self.adverarial_loss(y_hat_fake,y_fake)\n",
    "            \n",
    "            d_loss= (real_loss + fake_loss) / 2\n",
    "            \n",
    "            log_dict = {\"d_loss\" : d_loss }\n",
    "            return {\"loss\": d_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        lr=self.hparams.lr\n",
    "        opt_g = torch. optim.Adam(self.generator.parameters(),lr=lr)\n",
    "        opt_d = torch. optim.Adam(self.discriminator.parameters(),lr=lr)\n",
    "        return [opt_g,opt_d], []\n",
    "    \n",
    "    \n",
    "    def plot_imgs(self):\n",
    "        z= self.validation_z.type_as(self.generator.lin1.weight)\n",
    "        sample_imgs=self(z).cpu()\n",
    "        \n",
    "        print('epoch',self.current_epoch)\n",
    "        fig=plt.figure()\n",
    "        \n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(sample_imgs.detach()[i,0,:,:],cmap='gray_r',interpolation='none')\n",
    "            plt.title(\"Generated Data\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.axes('off')\n",
    "        plt.show()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.plot_imgs()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm =MNISTDataModule()\n",
    "\n",
    "model = GAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer =pl.Trainer(max_epochs=20,Gpus=AVAIL_GPUS)\n",
    "\n",
    "trainer.fit(model,dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('forpytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e142c631c90029d590b66e5d4b447237bff44b182aad6284fd72863ce8560c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
