{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Setting the random seed for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Defining the batch size, available GPUs, and number of workers\n",
    "BATCH_SIZE=1\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=int(os.cpu_count() / 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code imports various libraries required for building a deep learning model using PyTorch. It also sets the random seed to 42 for reproducibility of results.\n",
    "\n",
    "Furthermore, it defines the batch size for the data loader, the number of available GPUs, and the number of workers for the data loader to use.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CustomDataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.wavelet_files = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wavelet_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name=self.wavelet_files[idx]\n",
    "        wavelet_path = os.path.join(self.root_dir, file_name)\n",
    "        wavelet = pd.read_csv(wavelet_path,header=None).values\n",
    "        wavelet_tensor = torch.tensor(wavelet, dtype=torch.float32)\n",
    "        wavelet_tensor = wavelet_tensor.view(6, -1, wavelet_tensor.shape[1])\n",
    "        Label_Tag=file_name.split('_')\n",
    "        label=[]\n",
    "        for n in [1,3,5,7,9,11,13]:\n",
    "            temp_num=float(Label_Tag[n])\n",
    "            label.append(temp_num)\n",
    "        label=torch.tensor(label)\n",
    "    \n",
    "        return wavelet_tensor, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code defines a custom dataset class called ```CustomDataset```. The class takes in two parameters: ```root_dir``` and ```transform```, which represent the directory where the data is stored and any data transformation to be applied respectively.\n",
    "\n",
    "The ```__init__``` method initializes the dataset object with the specified ```root_dir``` and ```transform```. The ```__len__``` method returns the length of the dataset, which is the number of files in the ```root_dir```.\n",
    "\n",
    "The ```__getitem__``` method retrieves the data at the given index ```idx```. It reads the file name from the list of wavelet files in the ```root_dir```. It then reads the wavelet data from the CSV file at the path ```wavelet_path``` using pandas and converts it to a PyTorch tensor. The tensor is then reshaped to have 6 channels, with each channel having a shape that depends on the original shape of the wavelet data.\n",
    "\n",
    "The method then extracts the label information from the file name and converts it to a PyTorch tensor. It returns both the wavelet tensor and its corresponding label tensor as a tuple.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading wavelet image from CSV file\n",
    "test = pd.read_csv(\\\n",
    "    'Data/Wavelet_Image/Ron_50_Roff_50_Pulse_10_Vds_200_Vgson_17.5_Vgsoff_3_Resamplefac_50_id_1.csv',\\\n",
    "          header=None)\n",
    "\n",
    "# Printing the size of the wavelet image\n",
    "print(test.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code reads a wavelet image from a CSV file and stores it in a pandas DataFrame object called ```test```. The CSV file is located in the directory ```Data/Wavelet_Image``` and has the name ```Ron_50_Roff_50_Pulse_10_Vds_200_Vgson_17.5_Vgsoff_3_Resamplefac_50_id_1.csv```.\n",
    "\n",
    "The ```header=None``` argument indicates that there are no column headers in the CSV file.\n",
    "\n",
    "The second line of code prints the size of the ```test``` DataFrame using the ```size``` attribute. This prints the total number of elements in the DataFrame, which is equivalent to the number of rows multiplied by the number of columns.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the 2D data matrix to a 3D matrix\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_root, transform=None, batch_size=32, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.csv_root = csv_root   # Directory path where the CSV file is stored\n",
    "        self.batch_size = batch_size   # The batch size for the data loader\n",
    "        self.num_workers = num_workers   # The number of worker processes for loading the data\n",
    "        self.transform = transform   # Optional data transformation to be applied\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass   # Placeholder for any data preparation step, if needed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = CustomDataset(self.csv_root, transform=self.transform)   # Initialize the CustomDataset class with the specified CSV directory and transform\n",
    "        #self.dataset_train, self.dataset_val = random_split(self.dataset,[int(len(self.dataset)*0.7),len(self.dataset)-int(len(self.dataset)*0.7)])\n",
    "        self.dataset_train = self.dataset   # Set the training dataset to be the entire dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)   # Return a DataLoader object for the training data, which shuffles the data and divides it into batches\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)   # Return a DataLoader object for the validation data, which is set to be the same as the training data\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return None   # No test data is used for this model, so return None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code defines a PyTorch Lightning data module called ```CustomDataModule``` for loading the wavelet data. The ```CustomDataModule``` class inherits from the ```pl.LightningDataModule``` class.\n",
    "\n",
    "The ```__init__``` method initializes the data module object with the specified CSV root directory, batch size, and number of workers. The ```transform``` parameter is an optional argument that represents any data transformations to be applied.\n",
    "\n",
    "The ```prepare_data``` method does not have any functionality in this case, so it is left blank.\n",
    "\n",
    "The ```setup``` method initializes the dataset object with the specified CSV root directory and transform, using the ```CustomDataset``` class defined earlier.\n",
    "\n",
    "The ```train_dataloader``` method returns a PyTorch DataLoader object for training the model, using the DataLoader class from PyTorch. This ```DataLoader``` loads the training data from the ```dataset_train``` object, shuffles the data, and divides it into batches of size ```batch_size```.\n",
    "\n",
    "The ```val_dataloader``` method returns a PyTorch DataLoader object for validation, which is set to be the same as the training data.\n",
    "\n",
    "The ```test_dataloader``` method returns ```None```, indicating that no test data is used for this model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the root directory of the dataset\n",
    "root_dir = 'Data/Wavelet_Image/'\n",
    "\n",
    "# Defining the transformations for the dataset using PyTorch's Compose function\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Creating a custom dataset and dataloader using the CustomDataModule class\n",
    "data_module = CustomDataModule(root_dir, transform=transformations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code sets the root directory for the dataset to ```'Data/Wavelet_Image/'```.\n",
    "\n",
    "Next, data transformations are defined using PyTorch's ```Compose``` function. The ```transforms.ToTensor()``` function is used to convert the wavelet data to PyTorch tensors.\n",
    "\n",
    "Finally, a custom dataset and dataloader are created using the ```CustomDataModule``` class defined earlier. The ```root_dir``` and ```transform``` parameters are passed to the ```CustomDataModule``` constructor to specify the directory of the CSV files and the data transformation to be applied. The resulting ```data_module``` object can be used to load the wavelet data for training and validation.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data module and data loader\n",
    "data_module.setup()\n",
    "\n",
    "# Retrieve the training data from the data loader\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "\n",
    "# Get the first batch of data from the data loader\n",
    "i, l = next(iter(train_dataloader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code sets up the data module and data loader for the wavelet data using the ```setup``` method of the ```data_module``` object.\n",
    "\n",
    "Next, the training data is retrieved from the data loader using the ```train_dataloader``` method of the ```data_module``` object.\n",
    "\n",
    "Finally, the first batch of data from the training data loader is obtained using the ```next``` function and unpacked into two variables: ```i``` (input data) and ```l``` (labels). The ```next``` function returns the next batch of data as a tuple, which is why it is unpacked into two separate variables.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the shape of the input data and labels\n",
    "print(i.shape)\n",
    "print(l.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input Size [batch, 7]\n",
    "\n",
    "- Wavelet Size [batch, 6, 87, 25000]\n",
    "\n",
    "- We need to change the code while considering the data size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code prints the shape of the input data and labels obtained from the first batch of the training data loader.\n",
    "\n",
    "The ```i.shape``` prints the shape of the input data i, which should be a 3D tensor with dimensions ```(batch_size, num_channels, height, width)```, where ```batch_size``` is the number of samples in the batch, ```num_channels``` is the number of channels in the data (in this case, 6), and ```height``` and ```width``` are the height and width of the wavelet image, respectively.\n",
    "\n",
    "The ```l.shape``` prints the shape of the labels ```l```, which should be a 2D tensor with dimensions ```(batch_size, num_labels)```, where ```batch_size``` is the number of samples in the batch and ```num_labels``` is the number of labels in the data (in this case, 7).\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A discriminator model that determines if an image is real or fake, outputting a single value between 0 and 1\n",
    "\n",
    "## TODO: Change the Channel and input size\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Simple CNN architecture\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional and max pooling layers with ReLU activation\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # Flatten the tensor so it can be fed into the fully connected layers\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        # Apply sigmoid activation to output a value between 0 and 1\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code defines a PyTorch module called ```Discriminator``` that takes in wavelet images as input and outputs a single value between 0 and 1 indicating whether the input image is real or fake.\n",
    "\n",
    "The ```nn.Module``` class is used as the parent class for this custom module.\n",
    "\n",
    "The ```__init__``` method initializes the convolutional and fully connected layers of the model. The convolutional layers apply filters to the input wavelet images and the max pooling layers reduce the spatial dimensions of the output. The fully connected layers are used to reduce the output of the convolutional layers to a single value.\n",
    "\n",
    "The ```forward``` method applies the convolutional and max pooling layers with ReLU activation to the input tensor ```x```. The output is then flattened and passed through the fully connected layers with ReLU activation and dropout regularization. Finally, the output is passed through a sigmoid activation function to produce a single value between 0 and 1.\n",
    "\n",
    "The ```TODO``` comment indicates that the channel and input size should be changed to fit the specific dataset being used.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A generator model that takes a latent space vector as input and outputs a wavelet image\n",
    "\n",
    "## TODO: Change the Channel and input size\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        # Define the layers of the generator\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64)  # [n, 256, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 64, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through a linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)  #256\n",
    "        \n",
    "        # Upsample to 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Upsample to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply a convolutional layer to produce a 28x28 wavelet image with a single channel\n",
    "        return self.conv(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code defines a PyTorch module called ```Generator``` that takes a latent space vector as input and generates a wavelet image as output.\n",
    "\n",
    "The ```nn.Module``` class is used as the parent class for this custom module.\n",
    "\n",
    "The ```__init__``` method initializes the layers of the generator. The linear layer is used to transform the input latent space vector to a 3D tensor. The convolutional transpose layers are used to upsample the tensor, increasing the spatial dimensions and decreasing the number of channels. The final convolutional layer produces a 28x28 wavelet image with a single channel.\n",
    "\n",
    "The ```forward``` method takes the input tensor ```x``` and passes it through the layers of the generator, applying ReLU activation after each layer. The final output is a wavelet image of size 28x28 with a single channel.\n",
    "\n",
    "The ```TODO``` comment indicates that the channel and input size should be changed to fit the specific dataset being used.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Change the input Data using the label\n",
    "\n",
    "class GAN(pl.LightningDataModule):\n",
    "    def __init__(self, latent_dim=100, lr=0.0002):\n",
    "        super().__init__()\n",
    "        # Save the hyperparameters and initialize the generator and discriminator\n",
    "        self.save_hyperparameters()\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        # Create validation noise vector\n",
    "        self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def adverarial_loss(self, y_hat,y):\n",
    "        # Calculate binary cross-entropy loss\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_dim, optimizer_idx):   \n",
    "        real_imgs, labels = batch\n",
    "        \n",
    "        # Sample noise\n",
    "        z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(real_imgs)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            # Train the generator: maximize log(D(G(z)))\n",
    "            fake_imgs = self(z)\n",
    "            y_hat = self.discriminator(fake_imgs)\n",
    "            \n",
    "            y = torch.ones(real_imgs.size(0), 1)\n",
    "            y = y.type_as(real_imgs)\n",
    "            \n",
    "            g_loss = self.adverarial_loss(y_hat, y)\n",
    "            \n",
    "            log_dict = {\"g_loss\" : g_loss }\n",
    "            return {\"loss\": g_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            # Train the discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            y_hat_real = self.discriminator(real_imgs)\n",
    "            y_real = torch.ones(real_imgs.size(0), 1)\n",
    "            y_real = y_real.type_as(real_imgs)\n",
    "            real_loss = self.adverarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            y_hat_fake = self.discriminator(self(z))\n",
    "            y_fake = torch.zeros(real_imgs.size(0), 1)\n",
    "            y_fake = y_fake.type_as(real_imgs)\n",
    "            fake_loss = self.adverarial_loss(y_hat_fake, y_fake)\n",
    "            \n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            \n",
    "            log_dict = {\"d_loss\" : d_loss }\n",
    "            return {\"loss\": d_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        lr=self.hparams.lr\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        return [opt_g, opt_d], []\n",
    "    \n",
    "    def plot_imgs(self):\n",
    "        # Generate and plot validation images\n",
    "        z = self.validation_z.type_as(self.generator.lin1.weight)\n",
    "        sample_imgs = self(z).cpu()\n",
    "        \n",
    "        print('epoch', self.current_epoch)\n",
    "        fig = plt.figure()\n",
    "        for i in range(sample_imgs.size(0)):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(sample_imgs.detach()[i,0,:,:],cmap='gray_r',interpolation='none')\n",
    "            plt.title(\"Generated Data\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.axes('off')\n",
    "        plt.show()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # Call plot_imgs() at the end of each epoch\n",
    "        self.plot_imgs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block defines a PyTorch Lightning module called ```GAN``` that implements a generative adversarial network (GAN).\n",
    "\n",
    "The ```__init__``` method initializes the generator and discriminator networks, and creates a noise vector for validation.\n",
    "\n",
    "The ```forward``` method of the ```GAN``` class passes the noise vector through the generator network to generate images.\n",
    "\n",
    "The ```adverarial_loss``` method calculates the binary cross-entropy loss.\n",
    "\n",
    "The ```training_step``` method trains the generator and discriminator using the binary cross-entropy loss. It first trains the generator and then the discriminator.\n",
    "\n",
    "The ```configure_optimizers``` method sets the optimizers for the generator and discriminator.\n",
    "\n",
    "The ```plot_imgs``` method generates validation images and plots them.\n",
    "\n",
    "The ```on_epoch_end``` method is called at the end of each epoch and it calls the ```plot_imgs``` method.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the MNIST data module\n",
    "dm = MNISTDataModule()\n",
    "\n",
    "# Create an instance of the GAN model\n",
    "model = GAN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block creates an instance of the ```MNISTDataModule``` class and assigns it to the variable ```dm```. It also creates an instance of the ```GAN``` class and assigns it to the variable ```model```.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_imgs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```model.plot_imgs()``` generates validation images using the generator network and plots them. This method is defined in the ```GAN``` class and uses the validation noise vector ```validation_z``` defined in the constructor to generate the images. It then plots the generated images using Matplotlib.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the trainer object\n",
    "trainer = pl.Trainer(max_epochs=20, gpus=AVAIL_GPUS)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up a ```Trainer``` object with a maximum number of epochs and the number of available GPUs. It then trains the ```model``` using the ```Trainer``` object and the ```dm``` data module.\n",
    "\n",
    "The ```fit``` method of the ```Trainer``` object trains the ```model``` for the specified number of epochs using the data provided by the data module. During training, the ```on_epoch_end``` method of the ```GAN``` model is called after each epoch, which generates and plots validation images.\n",
    "\n",
    "After training is complete, the ```Trainer``` object returns a ```TrainerResult``` object with information about the training process, such as the final training and validation losses.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('forpytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e142c631c90029d590b66e5d4b447237bff44b182aad6284fd72863ce8560c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
