{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SMEET_SIMUL\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Setting the random seed for reproducibility\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Defining the batch size, available GPUs, and number of workers\n",
    "BATCH_SIZE=1\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=int(os.cpu_count() / 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code imports various libraries required for building a deep learning model using PyTorch. It also sets the random seed to 42 for reproducibility of results.\n",
    "\n",
    "Furthermore, it defines the batch size for the data loader, the number of available GPUs, and the number of workers for the data loader to use.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CustomDataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.FFT_files = os.listdir(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.FFT_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name=self.FFT_files[idx]\n",
    "        FFT_path = os.path.join(self.root_dir, file_name)\n",
    "        FFT = pd.read_csv(FFT_path,header=None).values\n",
    "        FFT_tensor = torch.tensor(FFT, dtype=torch.float32)\n",
    "        FFT_tensor = FFT_tensor.view(-1, FFT_tensor.shape[1])\n",
    "        Label_Tag=file_name.split('_')\n",
    "        label=[]\n",
    "        for n in [1,3,5,7,9,11,13]:\n",
    "            temp_num=float(Label_Tag[n])\n",
    "            label.append(temp_num)\n",
    "        label=torch.tensor(label)\n",
    "    \n",
    "        return FFT_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the 2D data matrix to a 3D matrix\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, csv_root, transform=None, batch_size=32, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.csv_root = csv_root   # Directory path where the CSV file is stored\n",
    "        self.batch_size = batch_size   # The batch size for the data loader\n",
    "        self.num_workers = num_workers   # The number of worker processes for loading the data\n",
    "        self.transform = transform   # Optional data transformation to be applied\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass   # Placeholder for any data preparation step, if needed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = CustomDataset(self.csv_root, transform=self.transform)   # Initialize the CustomDataset class with the specified CSV directory and transform\n",
    "        #self.dataset_train, self.dataset_val = random_split(self.dataset,[int(len(self.dataset)*0.7),len(self.dataset)-int(len(self.dataset)*0.7)])\n",
    "        self.dataset_train = self.dataset   # Set the training dataset to be the entire dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)   # Return a DataLoader object for the training data, which shuffles the data and divides it into batches\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)   # Return a DataLoader object for the validation data, which is set to be the same as the training data\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return None   # No test data is used for this model, so return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the root directory of the dataset\n",
    "root_dir = '../Data/FFT_Data/Turn_off'\n",
    "\n",
    "# Defining the transformations for the dataset using PyTorch's Compose function\n",
    "# transformations = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# Creating a custom dataset and dataloader using the CustomDataModule class\n",
    "data_module = CustomDataModule(root_dir, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data module and data loader\n",
    "data_module.setup()\n",
    "\n",
    "# Retrieve the training data from the data loader\n",
    "train_dataloader = data_module.train_dataloader()\n",
    "\n",
    "# Get the first batch of data from the data loader\n",
    "i, l = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 981])\n",
      "torch.Size([32, 7])\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of the input data and labels\n",
    "print(i.shape)\n",
    "print(l.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A discriminator model that determines if an image is real or fake, outputting a single value between 0 and 1\n",
    "\n",
    "## TODO: Change the Channel and input size\n",
    "\n",
    "# Start [batch, 3, 981] using 1-D Convolution, and using dialation for using data diffenrent part data \n",
    "# [batch, 3, 981] > [batch, 3, 979] > [batch, 3, 975] > [batch, 3, 967] > [batch, 3, 951] > [batch, 3, 919] > [batch, 3, 855] > [batch, 3, 727] > [batch, 3, 471] <[batch, 1, 469] \n",
    "# linear [469, 200, 1]\n",
    "#  \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # CNN architecture with dialation  references by TCN\n",
    "        self.conv1 = nn.Conv1d(3, 3, kernel_size=3,dilation=1)\n",
    "        self.conv2 = nn.Conv1d(3, 3, kernel_size=3,dilation=2)\n",
    "        self.conv3 = nn.Conv1d(3, 3, kernel_size=3,dilation=4)\n",
    "        self.conv4 = nn.Conv1d(3, 3, kernel_size=3,dilation=8)\n",
    "        self.conv5 = nn.Conv1d(3, 3, kernel_size=3,dilation=16)\n",
    "        self.conv6 = nn.Conv1d(3, 3, kernel_size=3,dilation=32)\n",
    "        self.conv7 = nn.Conv1d(3, 3, kernel_size=3,dilation=64)\n",
    "        self.conv8 = nn.Conv1d(3, 3, kernel_size=3,dilation=128)\n",
    "        self.conv9 = nn.Conv1d(3, 1, kernel_size=3)\n",
    "\n",
    "        # FCN\n",
    "        self.fc1 = nn.Linear(469, 200)\n",
    "        self.fc2 = nn.Linear(200, 1)\n",
    "\n",
    "        \n",
    "  \n",
    "    def forward(self, x):\n",
    "        # Apply convolutional and ReLU activation\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        # Flatten the tensor so it can be fed into the fully connected layers\n",
    "        temp_length=x.shape[2]\n",
    "        x = x.view(-1, temp_length)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply sigmoid activation to output a value between 0 and 1\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A generator model that takes a latent space vector as input and outputs a wavelet image\n",
    "\n",
    "## TODO: Change the Channel and input size\n",
    "# Input_size [batch,7]\n",
    "# End_size [batch, 3, 981]\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the layers of the generator\n",
    "        self.lin1 = nn.Linear(7, 7*7*64)  # [n, 64, 7, 7]\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2) # [n, 32, 16, 16]\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2) # [n, 16, 34, 34]\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)  # [n, 1, 28, 28]\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through a linear layer and reshape\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)  #256\n",
    "        \n",
    "        # Upsample to 16x16 (64 feature maps)\n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Upsample to 34x34 (16 feature maps)\n",
    "        x = self.ct2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply a convolutional layer to produce a 28x28 wavelet image with a single channel\n",
    "        return self.conv(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code defines a PyTorch module called ```Generator``` that takes a latent space vector as input and generates a wavelet image as output.\n",
    "\n",
    "The ```nn.Module``` class is used as the parent class for this custom module.\n",
    "\n",
    "The ```__init__``` method initializes the layers of the generator. The linear layer is used to transform the input latent space vector to a 3D tensor. The convolutional transpose layers are used to upsample the tensor, increasing the spatial dimensions and decreasing the number of channels. The final convolutional layer produces a 28x28 wavelet image with a single channel.\n",
    "\n",
    "The ```forward``` method takes the input tensor ```x``` and passes it through the layers of the generator, applying ReLU activation after each layer. The final output is a wavelet image of size 28x28 with a single channel.\n",
    "\n",
    "The ```TODO``` comment indicates that the channel and input size should be changed to fit the specific dataset being used.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Change the input Data using the label\n",
    "\n",
    "class GAN(pl.LightningDataModule):\n",
    "    def __init__(self, latent_dim=100, lr=0.0002):\n",
    "        super().__init__()\n",
    "        # Save the hyperparameters and initialize the generator and discriminator\n",
    "        self.save_hyperparameters()\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        # Create validation noise vector\n",
    "        self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "    \n",
    "    def adverarial_loss(self, y_hat,y):\n",
    "        # Calculate binary cross-entropy loss\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_dim, optimizer_idx):   \n",
    "        real_imgs, labels = batch\n",
    "        \n",
    "        # Sample noise\n",
    "        z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "        z = z.type_as(real_imgs)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            # Train the generator: maximize log(D(G(z)))\n",
    "            fake_imgs = self(z)\n",
    "            y_hat = self.discriminator(fake_imgs)\n",
    "            \n",
    "            y = torch.ones(real_imgs.size(0), 1)\n",
    "            y = y.type_as(real_imgs)\n",
    "            \n",
    "            g_loss = self.adverarial_loss(y_hat, y)\n",
    "            \n",
    "            log_dict = {\"g_loss\" : g_loss }\n",
    "            return {\"loss\": g_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            # Train the discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            y_hat_real = self.discriminator(real_imgs)\n",
    "            y_real = torch.ones(real_imgs.size(0), 1)\n",
    "            y_real = y_real.type_as(real_imgs)\n",
    "            real_loss = self.adverarial_loss(y_hat_real, y_real)\n",
    "            \n",
    "            y_hat_fake = self.discriminator(self(z))\n",
    "            y_fake = torch.zeros(real_imgs.size(0), 1)\n",
    "            y_fake = y_fake.type_as(real_imgs)\n",
    "            fake_loss = self.adverarial_loss(y_hat_fake, y_fake)\n",
    "            \n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            \n",
    "            log_dict = {\"d_loss\" : d_loss }\n",
    "            return {\"loss\": d_loss, \"progress bar\" : log_dict, \"log\": log_dict}\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        lr=self.hparams.lr\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "        return [opt_g, opt_d], []\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # Call plot_imgs() at the end of each epoch\n",
    "        self.plot_imgs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block defines a PyTorch Lightning module called ```GAN``` that implements a generative adversarial network (GAN).\n",
    "\n",
    "The ```__init__``` method initializes the generator and discriminator networks, and creates a noise vector for validation.\n",
    "\n",
    "The ```forward``` method of the ```GAN``` class passes the noise vector through the generator network to generate images.\n",
    "\n",
    "The ```adverarial_loss``` method calculates the binary cross-entropy loss.\n",
    "\n",
    "The ```training_step``` method trains the generator and discriminator using the binary cross-entropy loss. It first trains the generator and then the discriminator.\n",
    "\n",
    "The ```configure_optimizers``` method sets the optimizers for the generator and discriminator.\n",
    "\n",
    "The ```plot_imgs``` method generates validation images and plots them.\n",
    "\n",
    "The ```on_epoch_end``` method is called at the end of each epoch and it calls the ```plot_imgs``` method.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the MNIST data module\n",
    "\n",
    "\n",
    "# Create an instance of the GAN model\n",
    "model = GAN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block creates an instance of the ```MNISTDataModule``` class and assigns it to the variable ```dm```. It also creates an instance of the ```GAN``` class and assigns it to the variable ```model```.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_imgs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```model.plot_imgs()``` generates validation images using the generator network and plots them. This method is defined in the ```GAN``` class and uses the validation noise vector ```validation_z``` defined in the constructor to generate the images. It then plots the generated images using Matplotlib.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the trainer object\n",
    "trainer = pl.Trainer(max_epochs=20, gpus=AVAIL_GPUS)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block sets up a ```Trainer``` object with a maximum number of epochs and the number of available GPUs. It then trains the ```model``` using the ```Trainer``` object and the ```dm``` data module.\n",
    "\n",
    "The ```fit``` method of the ```Trainer``` object trains the ```model``` for the specified number of epochs using the data provided by the data module. During training, the ```on_epoch_end``` method of the ```GAN``` model is called after each epoch, which generates and plots validation images.\n",
    "\n",
    "After training is complete, the ```Trainer``` object returns a ```TrainerResult``` object with information about the training process, such as the final training and validation losses.\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('forpytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e142c631c90029d590b66e5d4b447237bff44b182aad6284fd72863ce8560c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
